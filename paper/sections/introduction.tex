A fundamental shift is occurring, beginning with the advent of the General Purpose Graphics Processing Unit (GPGPU) capable of much more processing than simply generating scenes for video games. This unit can handle specific workloads much more efficiently than a general CPU. While these workloads are specialized, in the increasingly parallel computing environments of today, it is finding much more use. However, it has been hampered by the large cost of moving massive amounts of data from the CPU onto the GPGPU's memory. To help bring the GPGPU to its fullest potential, it is getting swept into the CPU's increasing core count. Joining the general cores on the CPU itself. 

This shift comes with its own history spawning from GUI creators trying to solve their own unique problem to big data researchers realizing the similarities their problems have. As the GPU evolved, its creators were inadvertently (or perhaps, intentionally) created another general purpose processing unit that put the much more complicated CPU to shame on its own class of problems. 

This shift does not come without its own unique challenges. The GPGPU's single instruction multiple data (SIMD) class of computing differs wildly from the CPU's single instruction single data (SISD) class. This paper found that the differences can be classified into the following aspects: Control Flow, Memory Access, and Data Transfer. This paper will analyze all three differences, and analyze solutions to these problems. 


Reminder to tie back to his thesis about integrating GPGPUs reducing power load and circuit count. 
